# LLM-Fux Configuration
# Choose ONE mode: single_run OR batch_run. Set enabled: true for the mode you want.
# Then run: poetry run run-config

# =============================================================================
# GLOBAL SETTINGS (applied to all runs)
# =============================================================================

# API Settings
timeout: 600               # API timeout in seconds (600 = 10 minutes, 0 = no timeout)

# Directory Settings (usually don't need to change these)
data_dir: ./data
dataset: ""
outputs_dir: ./outputs

# =============================================================================
# MODEL DEFAULTS
# =============================================================================
# Default model versions for each provider (used when model_name is null)
# Update these when new model versions are released

models:
  openai: gpt-5.1-2025-11-13     # OpenAI ChatGPT model
  anthropic: claude-opus-4-5     # Anthropic Claude model  
  google: gemini-3-pro-preview   # Google Gemini model

# =============================================================================
# SINGLE RUN CONFIGURATION
# =============================================================================
# For testing one specific configuration repeatedly
# Set enabled: true, configure your test, then run: poetry run run-config

single_run:
  enabled: true            # Set to true to enable single run mode
  
  # Required
  file: Fux_CantusFirmus_C # File to test (e.g., Fux_CantusFirmus_C)
  
  # Test configuration
  model: gemini            # chatgpt, claude, or gemini
  model_name: null         # Specific model version (optional)
  datatype: musicxml       # musicxml, mei, abc, or humdrum
  guide_path: data/guides/Pierre-Guide.md  # Path to guide file (e.g., data/guides/LLM-Guide.md) or null for no guide
  
  # Model parameters
  temperature: 0.0         # 0.0-1.0
  max_tokens: 16000        # Maximum response length (16000 prevents truncation)

# =============================================================================
# BATCH RUN CONFIGURATION
# =============================================================================
# For testing multiple combinations (models × datatypes × files × contexts)
# Set enabled: true, configure your tests, then run: poetry run run-config

batch_run:
  enabled: false           # Set to true to enable batch run mode
  
  # What to test (list one or more of each)
  models:                  # One or more: chatgpt, claude, gemini
    # - claude
    # - chatgpt
    - gemini
  
  datatypes:               # One or more: musicxml, mei, abc, humdrum
    - musicxml
    # - mei
    # - abc
    # - humdrum
  
  files:                   # One or more file IDs
    - Fux_CantusFirmus_C
    - Fux_CantusFirmus_A
    - Fux_CantusFirmus_D
    - Fux_CantusFirmus_E
    - Fux_CantusFirmus_F
    - Fux_CantusFirmus_G
  
  # Context configuration
  contexts:                # Options: with, without (can include both!)
    # - without
    - with
  
  guide_path: data/guides/LLM-Guide.md  # Path to guide file when contexts includes "with"
  
  # Model parameters
  temperature: 0.0         # 0.0-1.0
  max_tokens: 16000        # Maximum response length
  
  # Execution settings
  delay: 2                 # Seconds between API calls (respects rate limits)
  parallel: 1              # Parallel jobs (1 = sequential, safer for rate limits)
  retry: 0                 # Retries on failure

# =============================================================================
# EXAMPLE CONFIGURATIONS
# =============================================================================
#
# Example 1: Test all models with MusicXML (no guide)
# batch_run:
#   enabled: true
#   models: [chatgpt, claude, gemini]
#   datatypes: [musicxml]
#   files: [Fux_CantusFirmus_C]
#   contexts: [without]
#
# Example 2: Test all formats with Claude
# batch_run:
#   enabled: true
#   models: [claude]
#   datatypes: [musicxml, mei, abc, humdrum]
#   files: [Fux_CantusFirmus_C]
#   contexts: [without]
#
# Example 3: Compare with/without context using LLM guide
# batch_run:
#   enabled: true
#   models: [claude]
#   datatypes: [musicxml]
#   files: [Fux_CantusFirmus_C]
#   contexts: [with, without]
#   guide_path: data/guides/LLM-Guide.md
#
# Example 4: Full comparison matrix with custom guide
# batch_run:
#   enabled: true
#   models: [chatgpt, claude, gemini]
#   datatypes: [musicxml, mei, abc, humdrum]
#   files: [Fux_CantusFirmus_C]
#   contexts: [with, without]
#   guide_path: data/guides/Pierre-Guide.md
