# LLM-Fux Configuration
# Edit these values to set your preferred defaults

# Model Configuration
model: claude              # Default provider: chatgpt, claude, or gemini
temperature: 0.0           # Sampling temperature (0.0-1.0)
max_tokens: 16000          # Maximum response tokens (set high to avoid truncation)
timeout: 600               # API timeout in seconds (600 = 10 minutes, 0 = no timeout)

# Input Settings
datatype: musicxml         # Default format: musicxml, mei, abc, humdrum

# Context Settings
guide: none                # Guide to use: LLM-Guide, Pierre-Guide, or none

# Directory Settings
data_dir: ./data
dataset: ""
outputs_dir: ./outputs

# Output Settings
save: true
overwrite: false

# Batch Settings (for run-batch command)
parallel: 1
retry: 0
